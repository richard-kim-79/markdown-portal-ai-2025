# app/main.py
import streamlit as st
from summarizer.summarizer import summarize_documents
from summarizer.tagger import generate_tags
from summarizer.markdown_generator import save_markdown
from db.models import (
    init_db,
    insert_document,
    get_all_documents,
    log_collection,
    get_recent_logs
)
from crawler.collector import collect_news_from_naver

# âœ… í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ğŸ§  Markdown Portal for AI 2025", layout="wide")
st.title("ğŸ“š Markdown Portal for AI 2025")
st.markdown("ë‰´ìŠ¤, ë¸”ë¡œê·¸, ë…¼ë¬¸ ë“±ì˜ ì›ë¬¸ì„ ìš”ì•½í•˜ê³  íƒœê¹…í•˜ë©°, ê²°ê³¼ë¥¼ Markdownìœ¼ë¡œ ì €ì¥í•˜ê³  DBì— ê¸°ë¡í•©ë‹ˆë‹¤.")

# âœ… DB ì´ˆê¸°í™”
init_db()

# âœ… ìˆ˜ì§‘ ë¡œê·¸ ë Œë” í•¨ìˆ˜
def render_log_entry(log):
    status_emoji = "âœ…" if log[3] == "success" else "âŒ"
    created = log[5][:19] if log[5] else "ì‹œê°„ ì—†ìŒ"
    source = log[1]
    keyword = log[2]
    message = log[4]
    st.markdown(f"{status_emoji} `{created}` | {source} | `{keyword}` â†’ {message}")

# âœ… ì €ì¥ëœ ë¬¸ì„œ í•„í„°ë§
def filter_documents(documents, title_filter, tag_filter, category_filter):
    results = []
    for doc in documents:
        title = doc[1] or ""
        tags = doc[4] or ""
        category = doc[5] or ""

        if (
            (not title_filter or title_filter.lower() in title.lower()) and
            (not tag_filter or tag_filter.lower() in tags.lower()) and
            (category_filter == "ì „ì²´" or category_filter == category)
        ):
            results.append(doc)
    return results

# ğŸ“¡ ìë™ ë‰´ìŠ¤ ìˆ˜ì§‘
if st.button("ğŸ“¡ ìë™ ë‰´ìŠ¤ ìˆ˜ì§‘"):
    with st.spinner("ğŸŒ€ ë„¤ì´ë²„ ë‰´ìŠ¤ì—ì„œ 'AI' ê´€ë ¨ ë¬¸ì„œ ìˆ˜ì§‘ ì¤‘..."):
        results = collect_news_from_naver(query="AI", max_articles=3)
        for article in results:
            title = article.get("title", "ì œëª© ì—†ìŒ")
            try:
                url = article.get("url")
                content = article.get("content")
                summary = summarize_documents(content)
                tags = generate_tags(summary)
                save_path = save_markdown(title, summary, tags, content)

                insert_document(title, content, summary, tags, "ë‰´ìŠ¤", url, str(save_path))
                log_collection("naver_news", "AI", "success", title)
                st.toast(f"âœ… ì €ì¥ ì™„ë£Œ: {title}")
            except Exception as e:
                log_collection("naver_news", "AI", "fail", f"{title} - {e}")
                st.error(f"âŒ {title} ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        st.success("âœ… ìë™ ìˆ˜ì§‘ ì™„ë£Œ!")

# âœï¸ ìˆ˜ë™ ì…ë ¥
with st.form("input_form"):
    url = st.text_input("ğŸ”— ì›ë³¸ URL", "")
    title = st.text_input("ğŸ“ ë¬¸ì„œ ì œëª©", "")
    category = st.selectbox("ğŸ“‚ ë¬¸ì„œ ìœ í˜• (ì¹´í…Œê³ ë¦¬)", ["ë‰´ìŠ¤", "ë¸”ë¡œê·¸", "ë…¼ë¬¸", "ê¸°íƒ€"])
    content = st.text_area("ğŸ“„ ì›ë¬¸ í…ìŠ¤íŠ¸", height=300)
    submitted = st.form_submit_button("ìš”ì•½ ë° ì €ì¥")

if submitted and content.strip():
    with st.spinner("ìš”ì•½ ì¤‘..."):
        try:
            summary = summarize_documents(content)
            tags = generate_tags(summary)
            save_path = save_markdown(title or "Untitled", summary, tags, content)
            insert_document(title, content, summary, tags, category, url, str(save_path))

            st.success("âœ… ì €ì¥ ì™„ë£Œ!")
            st.markdown(f"ğŸ“ ì €ì¥ ê²½ë¡œ: `{save_path}`")
            st.markdown("### âœ¨ ìš”ì•½ ê²°ê³¼")
            st.write(summary)
            st.markdown("### ğŸ—ï¸ íƒœê·¸")
            st.write(", ".join(tags))
        except Exception as e:
            st.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
elif submitted:
    st.warning("âš ï¸ ì›ë¬¸ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

# ğŸ” í•„í„° ë° ë¬¸ì„œ ëª©ë¡
st.markdown("---")
st.subheader("ğŸ” ë¬¸ì„œ ê²€ìƒ‰ í•„í„°")
search_title = st.text_input("ğŸ”¤ ì œëª© ê²€ìƒ‰")
search_tag = st.text_input("ğŸ·ï¸ íƒœê·¸ í¬í•¨")
search_category = st.selectbox("ğŸ—‚ï¸ ì¹´í…Œê³ ë¦¬ í•„í„°", ["ì „ì²´", "ë‰´ìŠ¤", "ë¸”ë¡œê·¸", "ë…¼ë¬¸", "ê¸°íƒ€"])

st.subheader("ğŸ“– ì €ì¥ëœ ìš”ì•½ ëª©ë¡")
documents = get_all_documents()
filtered_docs = filter_documents(documents, search_title, search_tag, search_category)

if filtered_docs:
    for doc in filtered_docs:
        title = doc[1] or "ì œëª© ì—†ìŒ"
        content = doc[2] or ""
        summary = doc[3] or ""
        tags = doc[4] or ""
        category = doc[5] or "ì¹´í…Œê³ ë¦¬ ì—†ìŒ"
        url = doc[6] or "ì—†ìŒ"
        path = doc[7] or ""
        created_at = doc[8][:19] if doc[8] else "ë‚ ì§œ ì—†ìŒ"

        with st.expander(f"ğŸ“Œ {title} | ğŸ—‚ï¸ {category} | ğŸ’ {created_at}"):
            st.markdown(f"**ğŸ”— URL:** {url}")
            st.markdown(f"**ğŸ“ ì›ë¬¸ ë‚´ìš©:**\n\n{content}")
            st.markdown(f"**ğŸ“Œ ìš”ì•½ ê²°ê³¼:**\n\n{summary}")
            st.markdown(f"**ğŸ·ï¸ íƒœê·¸:** {tags}")
            st.markdown(f"ğŸ“ ì €ì¥ ê²½ë¡œ: `{path}`")
else:
    st.info("ğŸ” ì¡°ê±´ì— ë§ëŠ” ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")

# ğŸªµ ìˆ˜ì§‘ ë¡œê·¸
st.markdown("---")
st.subheader("ğŸªµ ìˆ˜ì§‘ ë¡œê·¸")
for log in get_recent_logs(limit=10):
    render_log_entry(log)